{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sunny', 'warm', 'normal', 'strong', 'warm', 'same', 'yes'), ('sunny', 'warm', 'high', 'strong', 'warm', 'same', 'yes'), ('rainy', 'cold', 'high', 'strong', 'warm', 'change', 'no'), ('sunny', 'warm', 'high', 'strong', 'cool', 'change', 'yes')]\n",
      "[['rainy', 'sunny'], ['cold', 'warm'], ['high', 'normal'], ['strong'], ['cool', 'warm'], ['change', 'same']]\n",
      "\n",
      " G[0]: {('?', '?', '?', '?', '?', '?')}\n",
      "\n",
      " S[0]: {('0', '0', '0', '0', '0', '0')}\n",
      "\n",
      " G[1]: {('?', '?', '?', '?', '?', '?')}\n",
      "\n",
      " S[1]: {('sunny', 'warm', 'normal', 'strong', 'warm', 'same')}\n",
      "\n",
      " G[2]: {('?', '?', '?', '?', '?', '?')}\n",
      "\n",
      " S[2]: {('sunny', 'warm', '?', 'strong', 'warm', 'same')}\n",
      "\n",
      " G[3]: {('?', 'warm', '?', '?', '?', '?'), ('?', '?', '?', '?', '?', 'same'), ('sunny', '?', '?', '?', '?', '?')}\n",
      "\n",
      " S[3]: {('sunny', 'warm', '?', 'strong', 'warm', 'same')}\n",
      "\n",
      " G[4]: {('?', 'warm', '?', '?', '?', '?'), ('sunny', '?', '?', '?', '?', '?')}\n",
      "\n",
      " S[4]: {('sunny', 'warm', '?', 'strong', '?', '?')}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def get_domains(data):\n",
    "    d = [set() for _ in data[0]]\n",
    "    for x in data:\n",
    "        for i, value in enumerate(x):\n",
    "            d[i].add(value)\n",
    "    return list(sorted(x) for x in d)\n",
    "\n",
    "def consistent(hypothesis, sample):\n",
    "    more_general_parts = []\n",
    "    for x, y in zip(hypothesis, sample):\n",
    "        mg = x == \"?\" or (x != \"0\" and (x == y or y == \"0\"))\n",
    "        more_general_parts.append(mg)\n",
    "    return all(more_general_parts)\n",
    "\n",
    "\n",
    "def min_generalization(hypothesis, sample):\n",
    "    new_hypothesis = list(hypothesis)\n",
    "    for i, key in enumerate(hypothesis):\n",
    "        if not consistent(hypothesis[i], sample[i]):\n",
    "            new_hypothesis[i] = '?' if hypothesis[i] != '0' else sample[i]\n",
    "    return [tuple(new_hypothesis)]\n",
    "\n",
    "\n",
    "def min_specialization(hypothesis, sample, domain):\n",
    "    hypothesis = list(hypothesis)\n",
    "    results = []\n",
    "    for i, key in enumerate(hypothesis):\n",
    "        if hypothesis[i] == '?':\n",
    "            for val in domain[i]:\n",
    "                if sample[i] != val:\n",
    "                    new_hypothesis = hypothesis.copy()\n",
    "                    new_hypothesis[i] = val\n",
    "                    results.append(tuple(new_hypothesis))\n",
    "        elif hypothesis[i] == '0':\n",
    "            new_hypothesis = hypothesis.copy()\n",
    "            new_hypothesis[i] = '0'\n",
    "            results.append(tuple(new_hypothesis))\n",
    "    return results\n",
    "\n",
    "\n",
    "dataset = []\n",
    "with open('data1.csv') as csvfile:\n",
    "    lines = csv.reader(csvfile)\n",
    "    for row in list(lines)[1:]:\n",
    "        dataset.append(tuple(row))\n",
    "print(dataset)\n",
    "domains = get_domains(dataset)\n",
    "domains = domains[:-1]\n",
    "print(domains)\n",
    "# Initialize G to the set of maximally general hypotheses in H\n",
    "G = {(\"?\",) * len(domains)}\n",
    "# Initialize S to the set of maximally specific hypotheses in H\n",
    "S = {(\"0\",) * len(domains)}\n",
    "k = 0\n",
    "print(\"\\n G[{0}]:\".format(k), G)\n",
    "print(\"\\n S[{0}]:\".format(k), S)\n",
    "# For each training example d, do\n",
    "for i in dataset:\n",
    "    k += 1\n",
    "    attributes, output = i[:-1], i[-1]\n",
    "    # If d is a positive example\n",
    "    if output == 'yes':\n",
    "        # Remove from G any hypotheses inconsistent with d\n",
    "        G = {g for g in G if consistent(g, attributes)}\n",
    "        # For each hypothesis s in S that is not consistent with d\n",
    "        for s in list(S):\n",
    "            if not consistent(s, attributes):\n",
    "                # Remove s from S\n",
    "                S.remove(s)\n",
    "                # Add to S all minimal generalizations h of s such that\n",
    "                s_plus = min_generalization(s, attributes)\n",
    "                # h is consistent with d, and some member of G is more general than h\n",
    "                S.update([h for h in s_plus if any([consistent(g, h) for g in G])])\n",
    "    else:\n",
    "        # Remove from S any hypotheses inconsistent with d\n",
    "        S = {s for s in S if not consistent(s, attributes)}\n",
    "        for g in list(G):\n",
    "            if consistent(g, attributes):\n",
    "                G.remove(g)\n",
    "                g_minus = min_specialization(g, attributes, domains)\n",
    "                G.update([h for h in g_minus if any([consistent(h, s)\n",
    "                                                     for s in S])])\n",
    "\n",
    "    print(\"\\n G[{0}]:\".format(k), G)\n",
    "    print(\"\\n S[{0}]:\".format(k), S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
